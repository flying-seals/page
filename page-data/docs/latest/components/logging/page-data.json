{"componentChunkName":"component---src-views-docs-index-tsx","path":"/docs/latest/components/logging","webpackCompilationHash":"aefb7e842b40c338951f","result":{"pageContext":{"isCreatedByStatefulCreatePages":false,"version":"latest","versions":{"releases":["0.9"],"prereleases":["1.0"],"branches":["master"]},"content":{"id":"logging","displayName":"Logging","description":"Overall documentation for Logging","type":"components","docs":[{"order":"01-01-logging","title":"Overview","source":"\nLogging in Kyma uses [Loki](https://github.com/grafana/loki) which is a Prometheus-like log management system. This lightweight solution, integrated with Grafana, is easy to understand and operate. Loki provides Promtail which is a log router for Docker containers. Promtail runs inside Docker, checks each container and routes the logs to the log management system.\n\n> **NOTE:** At the moment, Kyma provides an alpha version of the Logging component.\n"},{"order":"02-01-logging","title":"Architecture","source":"\nThis document provides an overview of the logging architecture in Kyma. \n\n![Logging architecture in Kyma](./assets/loki-overview.png)\n\n## Agent (Promtail)\nPromtail is the agent responsible for collecting reliable metadata, consistent with the time series or metrics metadata. To achieve this, the agent uses the same service discovery and relabelling libraries as Prometheus. Promtail is used as a Deamon Set to discover targets, create metadata labels, and tail log files to produce a stream of logs. The logs are buffered on the client side and then sent to the service.\n\n## Log chunks\nA log chunk consists of all logs for metadata, such as labels, collected over a certain time period. Log chunks support append, seek, and stream operations on requests.\n\n## Life of a write request\nThe write request path resembles [Cortex](https://github.com/cortexproject/cortex) architecture, using the same server-side components. It looks as follows:\n1. The write request reaches the distributor service, which is responsible for distributing and replicating the requests to ingesters. Loki uses the Cortex consistent hash ring and distributes requests based on the hash of the entire metadata set.\n2. The write request goes to the log ingester which batches the requests for the same stream into the log chunks stored in memory. When the log chunks reach a predefined size or age, they are flushed out to the Cortex chunk store.\n3. The Cortex chunk store will be updated to reduce copying of chunk data on the read and write path and add support for writing chunks of google cloud storage.\n\n## Life of a query request\nLog chunks are larger than Prometheus Cortex chunks (Cortex chunks do not exceed 1KB). As a result, you cannot load and decompress them as a whole. \nTo solve this problem Loki supports streaming and iterating over the chunks. This means it can decompress only the necessary chunk parts.\n\nFor further information, see the [design documentation](https://docs.google.com/document/d/11tjK_lvp1-SVsFZjgOTr1vV3-q6vBAsZYIQ5ZeYBkyM/view).\n"},{"order":"03-01-access-logs","title":"Access logs","source":"\nTo access the logs, follow these steps:\n\n1. Run the following command to get the current Pod name:\n```bash\nkubectl get pods -l app=loki -n kyma-system\n```\n2. Run the following command to configure port forwarding, replace <pod_name> with output of previous command:\n```bash\nkubectl port-forward -n kyma-system <pod_name> 3100:3100\n```\n\n3. To get first 1000 lines of error logs for components in the 'kyma-system' Namespace, run the following command:\n```bash\ncurl -X GET -G 'http://localhost:3100/api/prom/query' --data-urlencode 'query={namespace=\"kyma-system\"}' --data-urlencode 'limit=1000' --data-urlencode 'regexp=error'\n```\n\nFor further information, see the [Loki API documentation](https://github.com/grafana/loki/blob/master/docs/api.md).\n","type":"Details"},{"order":"03-02-configure-storage","title":"Storage configuration","source":"\n## Storage\nBy default, Loki comes with the [boltDB](https://github.com/boltdb/bolt) storage configuration. It includes label and index storage, and the filesystem for object storage. Additionally, Loki supports other object stores, such as S3 or GCS.\n\nThis is an example of Loki configuration using boltDB and filesystem storage:\n```yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  labels:\n    app: loki\n  name: loki\ndata:\n  loki.yaml: |\n    auth_enabled: false\n\n    server:\n      http_listen_port: 3100\n\n    ingester:\n      lifecycler:\n        ring:\n          store: inmemory\n          replication_factor: 1\n    schema_config:\n      configs:\n      - from: 0\n        store: boltdb\n        object_store: filesystem\n        schema: v9\n        index:\n          prefix: index_\n          period: 168h\n    storage_configs:\n      - name: boltdb\n        directory: /tmp/loki/index\n      - name: filesystem\n        directory: /tmp/loki/chunks\n\n``` \n\nThe Loki storage configuration consists of the **schema_config** and **storage_configs** definitions. Use the **schema_config** to define your storage types, and **storage_configs** to configure the already defined storage types.\n\nA sample configuration for GCS looks as follows:\n\n```yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  labels:\n    app: loki\n  name: loki\ndata:\n  loki.yaml: |\n    auth_enabled: false\n\n    server:\n      http_listen_port: 3100\n\n    ingester:\n      lifecycler:\n        ring:\n          store: inmemory\n          replication_factor: 1\n    schema_config:\n      configs:\n      - from: 0\n        store: gcs\n        object_store: gsc\n        schema: v9\n        index:\n          prefix: index_\n          period: 168h\n    storage_configs:\n      gcs:\n        bucket_name: <YOUR_GCS_BUCKETNAME>\n        project: <BIG_TABLE_PROJECT_ID>\n        instance: <BIG_TABLE_INSTANCE_ID>\n        grpc_client_config: <YOUR_CLIENT_SETTINGS>\n       \n```\n","type":"Details"}]},"navigation":{"root":[{"displayName":"Kyma","id":"kyma"}],"components":[{"displayName":"Security","id":"security"},{"displayName":"Service Catalog","id":"service-catalog"},{"displayName":"Helm Broker","id":"helm-broker"},{"displayName":"Application Connector","id":"application-connector"},{"displayName":"Event Bus","id":"event-bus"},{"displayName":"Service Mesh","id":"service-mesh"},{"displayName":"Serverless","id":"serverless"},{"displayName":"Monitoring","id":"monitoring"},{"displayName":"Tracing","id":"tracing"},{"displayName":"API Gateway","id":"api-gateway"},{"displayName":"Logging","id":"logging"},{"displayName":"Backup","id":"backup"},{"displayName":"Console","id":"console"},{"displayName":"Asset Store","id":"asset-store"},{"displayName":"Headless CMS","id":"headless-cms"}]},"manifest":{"root":[{"displayName":"Kyma","id":"kyma"}],"components":[{"displayName":"Security","id":"security"},{"displayName":"Service Catalog","id":"service-catalog"},{"displayName":"Helm Broker","id":"helm-broker"},{"displayName":"Application Connector","id":"application-connector"},{"displayName":"Event Bus","id":"event-bus"},{"displayName":"Service Mesh","id":"service-mesh"},{"displayName":"Serverless","id":"serverless"},{"displayName":"Monitoring","id":"monitoring"},{"displayName":"Tracing","id":"tracing"},{"displayName":"API Gateway","id":"api-gateway"},{"displayName":"Logging","id":"logging"},{"displayName":"Backup","id":"backup"},{"displayName":"Console","id":"console"},{"displayName":"Asset Store","id":"asset-store"},{"displayName":"Headless CMS","id":"headless-cms"}]},"assetsPath":"/assets/docs/0.9/logging/docs/assets/","docsType":"components","topic":"logging","slidesBanner":{"bannerDuration":5000,"slides":[{"text":"Don't miss the session by Piotr Kopczynski at Helm Summit on September 11 at 15:47.","url":"https://helmsummit2019.sched.com/event/S8sS","startDate":"09/09/2019","endDate":"12/09/2019"}]},"locale":"en"}}}